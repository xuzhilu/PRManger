"""
LLMé…ç½®å’Œåˆå§‹åŒ–
"""

from langchain_ollama import ChatOllama
from langchain_core.messages import SystemMessage, HumanMessage
from .config import CONFIG
import json
import asyncio
from typing import Dict, Any, Optional, List
from datetime import datetime
import os


# LLMé…ç½®
OLLAMA_MODEL = CONFIG['llm']['model']
OLLAMA_BASE_URL = CONFIG['llm']['base_url']

# æ£€æŸ¥æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆæ˜¾ç¤ºLLMåŸå§‹å“åº”ï¼‰
DEBUG_SHOW_LLM_RESPONSE = CONFIG['llm'].get('debug_show_response', False)

# æ€§èƒ½ä¼˜åŒ–ï¼šé…ç½®LLMå‚æ•°ï¼ˆæ”¯æŒç»“æ„åŒ–è¾“å‡ºï¼‰
llm_kwargs = {
    "model": OLLAMA_MODEL,
    "base_url": OLLAMA_BASE_URL,
    "temperature": 0,  # é™ä½éšæœºæ€§ï¼Œæé«˜ç¨³å®šæ€§
    "num_predict": 16384,  # æœ€å¤§è¾“å‡ºé•¿åº¦
    "num_ctx": 81920,  # å¢åŠ ä¸Šä¸‹æ–‡çª—å£
    "num_gpu": -1,
    "num_thread": 4,
}

llm_kwargs["format"] = "json"

# æ˜¾ç¤ºè°ƒè¯•æ¨¡å¼çŠ¶æ€
if DEBUG_SHOW_LLM_RESPONSE:
    print("[LLM] ğŸ› è°ƒè¯•æ¨¡å¼å·²å¯ç”¨ï¼ˆå°†æ˜¾ç¤ºLLMåŸå§‹å“åº”ï¼‰")

llm = ChatOllama(**llm_kwargs)


class LLMResponseParser:
    """LLMå“åº”è§£æå™¨"""
    
    # æ·»åŠ è°ƒç”¨è¿½è¸ªï¼Œé˜²æ­¢é‡å¤æ—¥å¿—è¾“å‡º
    _call_tracking = {}
    _lock = asyncio.Lock()
    
    @staticmethod
    async def parse_json_with_retry(
        conversation: List,
        expected_schema: Dict[str, Any],
        max_retries: int = 3,
        parser_name: str = "unknown",
        timeout: int = 3600,
        custom_validator: Optional[callable] = None
    ) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨é‡è¯•æœºåˆ¶è§£æJSONå“åº”ï¼Œè®©LLMè‡ªæˆ‘ä¿®æ­£
        
        Args:
            conversation: å¯¹è¯å†å²
            expected_schema: æœŸæœ›çš„JSON schema
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            parser_name: è§£æå™¨åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            timeout: å•æ¬¡è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            custom_validator: è‡ªå®šä¹‰éªŒè¯å‡½æ•°ï¼Œæ¥æ”¶dictè¿”å›bool
            
        Returns:
            è§£æåçš„JSONå¯¹è±¡ï¼Œå¤±è´¥è¿”å›None
        """
        
        # ç”Ÿæˆå”¯ä¸€çš„è°ƒç”¨IDæ¥è¿½è¸ª
        import hashlib
        call_id = hashlib.md5(f"{parser_name}_{id(conversation)}_{datetime.now().timestamp()}".encode()).hexdigest()[:8]
        
        for attempt in range(max_retries):
            try:
                # ä½¿ç”¨é”é˜²æ­¢å¹¶å‘æ‰“å°
                async with LLMResponseParser._lock:
                    # æ£€æŸ¥æ˜¯å¦æœ€è¿‘å·²ç»æ‰“å°è¿‡ï¼ˆ1ç§’å†…ï¼‰
                    now = datetime.now().timestamp()
                    last_print_key = f"{parser_name}_{attempt}"
                    last_print_time = LLMResponseParser._call_tracking.get(last_print_key, 0)
                    
                    # åªæœ‰è·ç¦»ä¸Šæ¬¡æ‰“å°è¶…è¿‡1ç§’æ‰æ‰“å°
                    if now - last_print_time > 1.0:
                        print(f"[{parser_name}] ğŸ”„ å°è¯• {attempt + 1}/{max_retries}ï¼Œè¯·æ±‚LLMä¸­... (ID:{call_id})")
                        LLMResponseParser._call_tracking[last_print_key] = now
                        
                        # æ¸…ç†è¿‡æœŸçš„è¿½è¸ªè®°å½•ï¼ˆè¶…è¿‡10ç§’ï¼‰
                        LLMResponseParser._call_tracking = {
                            k: v for k, v in LLMResponseParser._call_tracking.items()
                            if now - v < 10
                        }
                
                # è°ƒç”¨LLMï¼ˆä½¿ç”¨JSONæ ¼å¼ï¼‰ï¼Œæ·»åŠ è¶…æ—¶å¤„ç†
                response = await asyncio.wait_for(
                    asyncio.to_thread(llm.invoke, conversation),
                    timeout=timeout
                )
                response_text = response.content
                
                # æå–tokenä½¿ç”¨ä¿¡æ¯
                token_info = ""
                if hasattr(response, 'response_metadata'):
                    metadata = response.response_metadata
                    if 'eval_count' in metadata or 'prompt_eval_count' in metadata:
                        prompt_tokens = metadata.get('prompt_eval_count', 0)
                        completion_tokens = metadata.get('eval_count', 0)
                        total_tokens = prompt_tokens + completion_tokens
                        token_info = f" [Token: è¾“å…¥={prompt_tokens}, è¾“å‡º={completion_tokens}, æ€»è®¡={total_tokens}]"
                
                print(f"[{parser_name}] âœ… æ”¶åˆ°å“åº”ï¼Œé•¿åº¦: {len(response_text)}{token_info}")
                
                # è°ƒè¯•æ¨¡å¼ï¼šæ˜¾ç¤ºLLMåŸå§‹å“åº”å’Œè¯¦ç»†tokenä¿¡æ¯
                if DEBUG_SHOW_LLM_RESPONSE:
                    print(f"\n{'='*60}")
                    print(f"[{parser_name}] ğŸ› LLMåŸå§‹å“åº”:")
                    print(f"{'='*60}")
                    
                    # æ˜¾ç¤ºè¯¦ç»†çš„tokenä½¿ç”¨ä¿¡æ¯
                    if hasattr(response, 'response_metadata'):
                        metadata = response.response_metadata
                        print(f"ğŸ“Š Tokenç»Ÿè®¡:")
                        print(f"  - è¾“å…¥tokens (prompt_eval_count): {metadata.get('prompt_eval_count', 'N/A')}")
                        print(f"  - è¾“å‡ºtokens (eval_count): {metadata.get('eval_count', 'N/A')}")
                        if 'prompt_eval_count' in metadata and 'eval_count' in metadata:
                            total = metadata.get('prompt_eval_count', 0) + metadata.get('eval_count', 0)
                            print(f"  - æ€»è®¡tokens: {total}")
                        if 'eval_duration' in metadata:
                            # è½¬æ¢çº³ç§’åˆ°ç§’
                            duration_s = metadata['eval_duration'] / 1e9
                            print(f"  - ç”Ÿæˆè€—æ—¶: {duration_s:.2f}ç§’")
                            if 'eval_count' in metadata and metadata['eval_count'] > 0:
                                tokens_per_sec = metadata['eval_count'] / duration_s
                                print(f"  - ç”Ÿæˆé€Ÿåº¦: {tokens_per_sec:.2f} tokens/ç§’")
                        print(f"{'='*60}")
                    
                    # å¦‚æœå“åº”å¾ˆé•¿ï¼Œåªæ˜¾ç¤ºå‰1000å­—ç¬¦
                    if len(response_text) > 1000:
                        print(response_text[:1000])
                        print(f"\n... (è¿˜æœ‰ {len(response_text) - 1000} ä¸ªå­—ç¬¦)")
                    else:
                        print(response_text)
                    print(f"{'='*60}\n")
                
                # å°è¯•è§£æJSON
                try:
                    result = json.loads(response_text)
                    print(f"[{parser_name}] ğŸ“ JSONè§£ææˆåŠŸï¼ŒéªŒè¯schemaä¸­...")
                    
                    # éªŒè¯schema - ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰éªŒè¯å™¨
                    if custom_validator:
                        if custom_validator(result):
                            print(f"[{parser_name}] âœ… è‡ªå®šä¹‰éªŒè¯é€šè¿‡ï¼Œè§£æå®Œæˆï¼")
                            return result
                        else:
                            print(f"[{parser_name}] âš ï¸ è‡ªå®šä¹‰éªŒè¯å¤±è´¥")
                            print(f"[{parser_name}] å®é™…å­—æ®µ: {list(result.keys())}")
                            error_msg = "JSONç»“æ„ä¸ç¬¦åˆè‡ªå®šä¹‰éªŒè¯è§„åˆ™"
                    elif LLMResponseParser._validate_schema(result, expected_schema):
                        print(f"[{parser_name}] âœ… SchemaéªŒè¯é€šè¿‡ï¼Œè§£æå®Œæˆï¼")
                        return result
                    else:
                        print(f"[{parser_name}] âš ï¸ SchemaéªŒè¯å¤±è´¥")
                        print(f"[{parser_name}] æœŸæœ›å­—æ®µ: {list(expected_schema.keys())}")
                        print(f"[{parser_name}] å®é™…å­—æ®µ: {list(result.keys())}")
                        error_msg = "JSONç»“æ„ä¸ç¬¦åˆé¢„æœŸschema"
                        
                except json.JSONDecodeError as e:
                    print(f"[{parser_name}] âš ï¸ JSONè§£æå¤±è´¥: {str(e)}")
                    print(f"[{parser_name}] å“åº”å‰200å­—ç¬¦: {response_text[:200]}...")
                    error_msg = f"JSONæ ¼å¼é”™è¯¯: {str(e)}"
                
                # è®°å½•å¤±è´¥
                LLMResponseParser._log_parse_failure(
                    parser_name=parser_name,
                    attempt=attempt + 1,
                    response_text=response_text,
                    error_msg=error_msg
                )
                
                # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œè®©LLMè‡ªæˆ‘ä¿®æ­£
                if attempt < max_retries - 1:
                    print(f"[{parser_name}] ğŸ”„ å‡†å¤‡é‡è¯• {attempt + 2}/{max_retries}ï¼Œè¯·æ±‚LLMè‡ªæˆ‘ä¿®æ­£...")
                    
                    conversation.append(HumanMessage(content=response_text))
                    conversation.append(HumanMessage(content=f"""
ä¸Šä¸€æ¬¡çš„å“åº”è§£æå¤±è´¥ï¼š{error_msg}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚é‡æ–°ç”Ÿæˆï¼š
1. åªè¾“å‡ºçº¯JSONï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—
2. ä¸è¦ä½¿ç”¨markdownä»£ç å—æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰
3. ç¡®ä¿JSONæ ¼å¼å®Œå…¨æ­£ç¡®ï¼ˆåŒå¼•å·ã€é€—å·ã€æ‹¬å·åŒ¹é…ï¼‰
4. å¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µï¼š{list(expected_schema.keys())}

è¯·é‡æ–°è¾“å‡ºï¼š
"""))
                    
            except asyncio.TimeoutError:
                print(f"[{parser_name}] â±ï¸ è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
                LLMResponseParser._log_parse_failure(
                    parser_name=parser_name,
                    attempt=attempt + 1,
                    response_text="",
                    error_msg=f"Timeout after {timeout} seconds"
                )
                
                if attempt < max_retries - 1:
                    print(f"[{parser_name}] å°†åœ¨ä¸‹æ¬¡å°è¯•ä¸­ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´...")
                    timeout = int(timeout * 1.5)  # å¢åŠ è¶…æ—¶æ—¶é—´
                    
            except Exception as e:
                print(f"[{parser_name}] âŒ å¼‚å¸¸: {str(e)}")
                import traceback
                print(f"[{parser_name}] å †æ ˆè¿½è¸ª:\n{traceback.format_exc()}")
                LLMResponseParser._log_parse_failure(
                    parser_name=parser_name,
                    attempt=attempt + 1,
                    response_text="",
                    error_msg=f"Exception: {str(e)}\n{traceback.format_exc()}"
                )
                
                if attempt < max_retries - 1:
                    conversation.append(HumanMessage(content=f"å‘ç”Ÿé”™è¯¯: {str(e)}ï¼Œè¯·é‡è¯•"))
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        print(f"[{parser_name}] âŒ æ‰€æœ‰é‡è¯•å‡å¤±è´¥")
        return None
    
    @staticmethod
    def _validate_schema(data: Dict[str, Any], schema: Dict[str, Any]) -> bool:
        """éªŒè¯JSONæ˜¯å¦ç¬¦åˆschema"""
        # ç®€å•éªŒè¯ï¼šæ£€æŸ¥å¿…éœ€å­—æ®µæ˜¯å¦å­˜åœ¨
        for key in schema.keys():
            if key not in data:
                print(f"ç¼ºå°‘å­—æ®µ: {key}")
                return False
        return True
    
    @staticmethod
    def _log_parse_failure(
        parser_name: str,
        attempt: int,
        response_text: str,
        error_msg: str
    ):
        """è®°å½•è§£æå¤±è´¥çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            # ç¡®ä¿logsç›®å½•å­˜åœ¨
            log_dir = "logs/parse_failures"
            os.makedirs(log_dir, exist_ok=True)
            
            # ç”Ÿæˆæ—¥å¿—æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            log_file = os.path.join(
                log_dir,
                f"{parser_name}_{timestamp}_attempt{attempt}.log"
            )
            
            # å†™å…¥æ—¥å¿—
            with open(log_file, 'w', encoding='utf-8') as f:
                f.write(f"Parser: {parser_name}\n")
                f.write(f"Attempt: {attempt}\n")
                f.write(f"Timestamp: {timestamp}\n")
                f.write(f"Error: {error_msg}\n")
                f.write(f"\n{'='*60}\n")
                f.write(f"Response Text:\n")
                f.write(f"{'='*60}\n")
                f.write(response_text)
            
            print(f"[{parser_name}] ğŸ“ å¤±è´¥æ—¥å¿—å·²ä¿å­˜: {log_file}")
            
        except Exception as e:
            print(f"[{parser_name}] âš ï¸ æ— æ³•ä¿å­˜æ—¥å¿—: {str(e)}")


# å¯¼å‡ºè§£æå™¨
parser = LLMResponseParser()
