"""
PRæ‹†åˆ†æ™ºèƒ½ä½“
"""

import re
import json
from typing import List, Dict, Set, Tuple
from langchain_core.messages import SystemMessage, HumanMessage
from langgraph.config import get_stream_writer
from src.core.state import PRReviewState
from src.utils.helpers import calculate_pr_size
from src.utils.config import CONFIG


async def pr_splitter_node(state: PRReviewState) -> PRReviewState:
    """PRæ‹†åˆ†æ™ºèƒ½ä½“èŠ‚ç‚¹
    
    èŒè´£ï¼š
    1. ä»Gitè·å–åˆ†æ”¯diffå†…å®¹
    2. è¯„ä¼°PRè§„æ¨¡
    3. åˆ¤æ–­æ˜¯å¦éœ€è¦æ‹†åˆ†
    4. å¦‚æœéœ€è¦æ‹†åˆ†ï¼Œå°†PRæŒ‰æ¨¡å—æ‹†åˆ†ä¸ºå¤šä¸ªå­PR
    """
    print("\n" + "="*60)
    print("=== PRæ‹†åˆ†æ™ºèƒ½ä½“ ===")
    print("="*60)
    writer = get_stream_writer()
    writer({"stage": "pr_splitter", "status": "started"})
    
    source_branch = state.get("source_branch")
    target_branch = state.get("target_branch")
    
    if not all([source_branch, target_branch]):
        print("[é”™è¯¯] åˆ†æ”¯ä¿¡æ¯ä¸å®Œæ•´")
        return {
            "current_stage": "splitter_failed",
            "feedback_message": "åˆ†æ”¯ä¿¡æ¯ä¸å®Œæ•´"
        }
    
    # ä½¿ç”¨å…¨å±€git_adapter
    from src.adapters.git_adapter import get_git_adapter
    git_adapter = get_git_adapter()
    
    # 1. è·å–åˆ†æ”¯diffä¿¡æ¯
    print(f"[æ­¥éª¤1] è·å–åˆ†æ”¯diff: {source_branch} â†’ {target_branch}")
    try:
        branch_info = await git_adapter.get_branch_diff(source_branch, target_branch)
        writer({"branch_info_fetched": True})
        print("[æ­¥éª¤1] âœ“ æˆåŠŸè·å–diffä¿¡æ¯")
    except Exception as e:
        print(f"[æ­¥éª¤1] âœ— è·å–å¤±è´¥: {e}")
        writer({"error": str(e)})
        return {
            "current_stage": "splitter_failed",
            "feedback_message": f"è·å–åˆ†æ”¯ä¿¡æ¯å¤±è´¥ï¼š{str(e)}"
        }
    
    pr_diff = branch_info.get("diff", "")
    branch_content = branch_info.get("content", {})
    pr_files = branch_info.get("files", [])
    
    # 2. è¯„ä¼°PRè§„æ¨¡
    print("[æ­¥éª¤2] è¯„ä¼°PRè§„æ¨¡...")
    pr_size, pr_stats = calculate_pr_size(pr_diff, pr_files)
    
    print(f"[æ­¥éª¤2] âœ“ PRè§„æ¨¡: {pr_size.upper()}")
    print(f"        æ–‡ä»¶æ•°: {pr_stats.get('files_count', 0)}")
    print(f"        ä»£ç è¡Œ: +{pr_stats.get('additions', 0)} -{pr_stats.get('deletions', 0)}")
    
    writer({"pr_size_evaluation": {
        "pr_size": pr_size,
        "stats": pr_stats
    }})
    
    # 3. åˆ¤æ–­æ˜¯å¦éœ€è¦æ‹†åˆ†
    print("\n[æ­¥éª¤3] åˆ¤æ–­æ˜¯å¦éœ€è¦æ‹†åˆ†...")
    needs_split = _should_split_pr(pr_size, pr_stats, pr_files)
    
    if not needs_split:
        print("[æ­¥éª¤3] âœ“ PRè§„æ¨¡é€‚ä¸­ï¼Œæ— éœ€æ‹†åˆ†")
        print("[æ­¥éª¤3] ä¸‹ä¸€æ­¥: å•ä¸ªPRå¤„ç†ï¼ˆå­å›¾ï¼‰")
        print("="*60 + "\n")
        
        return {
            "pr_diff": pr_diff,
            "pr_files": pr_files,
            "pr_size": pr_size,
            "pr_stats": pr_stats,
            "needs_split": False,
            "is_sub_pr": False,
            "current_stage": "single_pr_review"  # æ–°é˜¶æ®µï¼šç›´æ¥è¿›å…¥å•PRå¤„ç†å­å›¾
        }
    
    # 4. æ‰§è¡Œæ‹†åˆ†
    print("[æ­¥éª¤3] âš ï¸ PRè§„æ¨¡è¾ƒå¤§ï¼Œéœ€è¦æ‹†åˆ†")
    print("\n[æ­¥éª¤4] æ‰§è¡Œæ™ºèƒ½æ‹†åˆ†...")
    
    sub_prs = await _split_pr_by_modules(pr_diff, pr_files, pr_stats)
    
    if not sub_prs or len(sub_prs) <= 1:
        print("[æ­¥éª¤4] âš ï¸ æ‹†åˆ†å¤±è´¥æˆ–æ‹†åˆ†åä»ä¸ºå•ä¸ªPRï¼Œä½¿ç”¨åŸå§‹PR")
        return {
            "pr_diff": pr_diff,
            "pr_files": pr_files,
            "pr_size": pr_size,
            "pr_stats": pr_stats,
            "needs_split": False,
            "is_sub_pr": False,
            "current_stage": "single_pr_review"  # é™çº§ä¸ºå•PRå¤„ç†
        }
    
    print(f"[æ­¥éª¤4] âœ“ æˆåŠŸæ‹†åˆ†ä¸º {len(sub_prs)} ä¸ªå­PR")
    for i, sub_pr in enumerate(sub_prs, 1):
        print(f"        å­PR {i}: {sub_pr.get('title', f'SubPR-{i}')} ({len(sub_pr.get('files', []))} ä¸ªæ–‡ä»¶)")
    
    print("\n[æ‹†åˆ†å®Œæˆ] ä¸‹ä¸€æ­¥: æ‰¹é‡å¤„ç†å„å­PRï¼ˆå¾ªç¯å­å›¾ï¼‰")
    print("="*60 + "\n")
    
    writer({"split_result": {
        "sub_prs_count": len(sub_prs),
        "sub_prs": [{"title": sp.get("title"), "files_count": len(sp.get("files", []))} for sp in sub_prs]
    }})
    
    return {
        "pr_diff": pr_diff,
        "pr_files": pr_files,
        "pr_size": pr_size,
        "pr_stats": pr_stats,
        "needs_split": True,
        "sub_prs": sub_prs,
        "sub_pr_results": [],
        "is_sub_pr": False,
        "parent_pr_id": f"{source_branch}_{target_branch}",
        "current_stage": "sub_pr_review"  # æ–°é˜¶æ®µï¼šè¿›å…¥æ‰¹é‡å­PRå¤„ç†ï¼ˆå¾ªç¯å­å›¾ï¼‰
    }


def _should_split_pr(pr_size: str, pr_stats: Dict, pr_files: List) -> bool:
    """åˆ¤æ–­PRæ˜¯å¦éœ€è¦æ‹†åˆ†
    
    æ‹†åˆ†ä¾æ®ï¼šdiffå­—èŠ‚æ•°æ˜¯å¦è¶…è¿‡é…ç½®é˜ˆå€¼
    """
    # ä»é…ç½®è¯»å–æ‹†åˆ†é˜ˆå€¼
    splitting_config = CONFIG.get('pr_review', {}).get('splitting', {})
    thresholds = splitting_config.get('thresholds', {})
    
    # ä½¿ç”¨diff_sizeä½œä¸ºå”¯ä¸€æ‹†åˆ†æ ‡å‡†
    diff_size = pr_stats.get('diff_size', 0)
    diff_size_threshold = thresholds.get('diff_size', 50000)
    
    if diff_size > diff_size_threshold:
        
        return True
    return False


async def _split_pr_by_modules(pr_diff: str, pr_files: List[Dict], pr_stats: Dict) -> List[Dict]:
    """ä½¿ç”¨ä¾èµ–å…³ç³»æ„ŸçŸ¥çš„æ™ºèƒ½æ‹†åˆ†
    
    ç­–ç•¥ï¼š
    0. åˆ†ææ–‡ä»¶é—´ä¾èµ–å…³ç³»ï¼Œæ„å»ºä¾èµ–ç»„
    1. æŒ‰ç›®å½•åˆ†ç»„ï¼Œä½†ä¿æŒä¾èµ–ç»„å®Œæ•´æ€§
    2. å¦‚æœè§„åˆ™æ‹†åˆ†å¤±è´¥ï¼Œé™çº§ä¸ºæŒ‰æ–‡ä»¶æ•°é‡å‡åˆ†
    """
    print("[æ‹†åˆ†ç­–ç•¥] ä½¿ç”¨ä¾èµ–å…³ç³»æ„ŸçŸ¥çš„æ™ºèƒ½æ‹†åˆ†...")
    
    # ä»é…ç½®è¯»å–è®¾ç½®
    splitting_config = CONFIG.get('pr_review', {}).get('splitting', {})
    target_diff_size = splitting_config.get('target_diff_size', 50000)
    enable_dependency_analysis = splitting_config.get('enable_dependency_analysis', True)
    
    # æå–æ–‡ä»¶è·¯å¾„ä¿¡æ¯
    file_paths = []
    for file_info in pr_files:
        if isinstance(file_info, dict):
            file_path = file_info.get('path', file_info.get('filename', ''))
        else:
            file_path = str(file_info)
        if file_path:
            file_paths.append(file_path)
    
    # æŒ‰æ–‡ä»¶æ‹†åˆ†diff
    file_diffs = _split_diff_by_file(pr_diff)
    
    # æ­¥éª¤0: åˆ†æä¾èµ–å…³ç³»
    dependency_groups = []
    if enable_dependency_analysis:
        print("[ä¾èµ–åˆ†æ] ğŸ” åˆ†ææ–‡ä»¶é—´ä¾èµ–å…³ç³»...")
        dependency_groups = _analyze_and_group_dependencies(file_paths, file_diffs)
        
        if dependency_groups:
            print(f"[ä¾èµ–åˆ†æ] âœ“ å‘ç° {len(dependency_groups)} ä¸ªä¾èµ–ç»„")
            for i, group in enumerate(dependency_groups, 1):
                group_size = sum(len(file_diffs.get(f, '').encode('utf-8')) for f in group)
                print(f"        - ä¾èµ–ç»„ {i}: {len(group)} ä¸ªæ–‡ä»¶, {group_size} bytes")
                for f in group[:3]:
                    print(f"          â€¢ {f}")
                if len(group) > 3:
                    print(f"          ... è¿˜æœ‰ {len(group)-3} ä¸ªæ–‡ä»¶")
            
            # æ‰¾å‡ºç‹¬ç«‹æ–‡ä»¶
            files_in_groups = set()
            for group in dependency_groups:
                files_in_groups.update(group)
            
            independent_files = [f for f in file_paths if f not in files_in_groups]
            if independent_files:
                for f in independent_files:
                    dependency_groups.append([f])
                print(f"[ä¾èµ–åˆ†æ] â„¹ï¸ å¦æœ‰ {len(independent_files)} ä¸ªç‹¬ç«‹æ–‡ä»¶ï¼ˆæ— ä¾èµ–å…³ç³»ï¼‰")
        else:
            dependency_groups = [[f] for f in file_paths]
            print("[ä¾èµ–åˆ†æ] â„¹ï¸ æœªå‘ç°æ–‡ä»¶é—´ä¾èµ–ï¼Œæ‰€æœ‰æ–‡ä»¶ç‹¬ç«‹")
    else:
        dependency_groups = [[f] for f in file_paths]
        print("[ä¾èµ–åˆ†æ] âš ï¸ ä¾èµ–åˆ†æå·²ç¦ç”¨ï¼Œæ‰€æœ‰æ–‡ä»¶ç‹¬ç«‹å¤„ç†")
    
    # ç­–ç•¥1: ä¼˜å…ˆæŒ‰ä¾èµ–ç»„æ‹†åˆ†ï¼ˆä¿è¯ä¾èµ–å®Œæ•´æ€§ï¼‰
    if len(dependency_groups) > 1:
        print(f"[æ‹†åˆ†ç­–ç•¥] âœ“ å‘ç°å¤šä¸ªä¾èµ–ç»„ï¼Œç›´æ¥æŒ‰ä¾èµ–ç»„æ‹†åˆ†ï¼ˆå…± {len(dependency_groups)} ç»„ï¼‰")
        return _split_by_dependency_groups(dependency_groups, file_diffs)
    
    # ç­–ç•¥2: æŒ‰ç›®å½•åˆ†ç»„ï¼ˆä¿æŒä¾èµ–ç»„å®Œæ•´ï¼‰
    print("[æ‹†åˆ†ç­–ç•¥] åªæœ‰1ä¸ªä¾èµ–ç»„ï¼Œå°è¯•æŒ‰ç›®å½•åˆ†ç»„...")
    module_groups = _group_dependency_aware_by_directory(dependency_groups, file_diffs, target_diff_size)
    
    if len(module_groups) > 1:
        print(f"[æ‹†åˆ†ç­–ç•¥] âœ“ æŒ‰ç›®å½•åˆ†ç»„æˆåŠŸï¼Œå…± {len(module_groups)} ä¸ªæ¨¡å—")
        sub_prs = []
        for module_name, files_info in module_groups.items():
            sub_pr = {
                "title": f"[å­PR] {module_name}",
                "files": files_info['files'],
                "diff": files_info['diff'],
                "module": module_name
            }
            sub_prs.append(sub_pr)
        return sub_prs
    
    # ç­–ç•¥3: ç®€å•å‡åˆ†ï¼ˆæ¯ä¸ªå­PRæœ€å¤š5ä¸ªæ–‡ä»¶ï¼Œé¿å…ç ´åä¾èµ–ï¼‰
    print("[æ‹†åˆ†ç­–ç•¥] ç›®å½•åˆ†ç»„å¤±è´¥ï¼Œä½¿ç”¨ç®€å•å‡åˆ†ç­–ç•¥ï¼ˆä¿æŒä¾èµ–ç»„å®Œæ•´ï¼‰...")
    chunk_size = 5
    sub_prs = []
    
    for i in range(0, len(file_paths), chunk_size):
        chunk_files = file_paths[i:i+chunk_size]
        chunk_diff = "\n".join([file_diffs.get(f, "") for f in chunk_files])
        
        sub_pr = {
            "title": f"[å­PR] æ–‡ä»¶ç»„ {i//chunk_size + 1}",
            "files": [{"path": f} for f in chunk_files],
            "diff": chunk_diff,
            "module": f"group_{i//chunk_size + 1}"
        }
        sub_prs.append(sub_pr)
    
    print(f"[æ‹†åˆ†ç­–ç•¥] âœ“ å‡åˆ†å®Œæˆï¼Œå…± {len(sub_prs)} ä¸ªå­PR")
    return sub_prs

def _split_diff_by_file(pr_diff: str) -> Dict:
    """å°†diffæŒ‰æ–‡ä»¶åˆ†å‰²"""
    file_diffs = {}
    current_file = None
    current_content = []
    
    for line in pr_diff.split('\n'):
        if line.startswith('diff --git'):
            if current_file:
                file_diffs[current_file] = '\n'.join(current_content)
            # æå–æ–‡ä»¶å
            match = re.search(r'b/(.+)$', line)
            current_file = match.group(1) if match else 'unknown'
            current_content = [line]
        elif current_file:
            current_content.append(line)
    
    if current_file:
        file_diffs[current_file] = '\n'.join(current_content)
    
    return file_diffs


def _analyze_and_group_dependencies(file_paths: List[str], file_diffs: Dict) -> List[List[str]]:
    """åˆ†ææ–‡ä»¶é—´ä¾èµ–å…³ç³»å¹¶æ„å»ºä¾èµ–ç»„
    
    ä½¿ç”¨å¹¶æŸ¥é›†ï¼ˆUnion-Findï¼‰å°†æœ‰ä¾èµ–çš„æ–‡ä»¶åˆ†ç»„
    """
    # æ­¥éª¤1: æå–æ¯ä¸ªæ–‡ä»¶ä¸­å˜æ›´çš„å®šä¹‰
    file_definitions = {}
    for file_path in file_paths:
        diff = file_diffs.get(file_path, '')
        definitions = _extract_changed_definitions_from_diff(diff)
        if definitions:
            file_definitions[file_path] = definitions
    
    if not file_definitions:
        return []
    
    # æ­¥éª¤2: æ„å»ºä¾èµ–å›¾
    dependencies = {}
    for file_path in file_paths:
        diff = file_diffs.get(file_path, '')
        deps = set()
        
        for other_file, defs in file_definitions.items():
            if other_file == file_path:
                continue
            
            for def_name, def_type in defs:
                if _has_reference_in_diff(diff, def_name, def_type):
                    deps.add(other_file)
                    print(f"        [ä¾èµ–] {file_path} â†’ {other_file} (ä½¿ç”¨äº† {def_type}: {def_name})")
        
        if deps:
            dependencies[file_path] = list(deps)
    
    # æ­¥éª¤3: ä½¿ç”¨å¹¶æŸ¥é›†æ„å»ºä¾èµ–ç»„
    parent = {f: f for f in file_paths}
    
    def find(x):
        if parent[x] != x:
            parent[x] = find(parent[x])
        return parent[x]
    
    def union(x, y):
        px, py = find(x), find(y)
        if px != py:
            parent[px] = py
    
    for file_a, dep_files in dependencies.items():
        for file_b in dep_files:
            union(file_a, file_b)
    
    groups_dict = {}
    for file_path in file_paths:
        root = find(file_path)
        if root not in groups_dict:
            groups_dict[root] = []
        groups_dict[root].append(file_path)
    
    dependency_groups = [group for group in groups_dict.values() if len(group) > 1]
    return dependency_groups


def _extract_changed_definitions_from_diff(diff: str) -> List[Tuple[str, str]]:
    """ä»diffä¸­æå–è¢«ä¿®æ”¹æˆ–æ–°å¢çš„å®šä¹‰"""
    definitions = []
    
    func_patterns = [
        r'^[-+]\s*(?:virtual\s+)?(?:static\s+)?(\w+)\s+(\w+)\s*\([^)]*\)',
        r'^[-+]\s*def\s+(\w+)\s*\(',
        r'^[-+]\s*function\s+(\w+)\s*\(',
    ]
    
    class_patterns = [
        r'^[-+]\s*class\s+(\w+)',
        r'^[-+]\s*struct\s+(\w+)',
    ]
    
    for line in diff.split('\n'):
        for pattern in func_patterns:
            match = re.search(pattern, line)
            if match:
                func_name = match.group(2) if len(match.groups()) > 1 else match.group(1)
                if func_name not in ['if', 'while', 'for', 'switch', 'catch', 'return']:
                    definitions.append((func_name, 'function'))
                    break
        
        for pattern in class_patterns:
            match = re.search(pattern, line)
            if match:
                definitions.append((match.group(1), 'class'))
                break
    
    return list(set(definitions))


def _has_reference_in_diff(diff: str, name: str, def_type: str) -> bool:
    """æ£€æŸ¥diffä¸­æ˜¯å¦å¼•ç”¨äº†æŒ‡å®šçš„å®šä¹‰"""
    escaped_name = re.escape(name)
    added_lines = [line for line in diff.split('\n') if line.startswith('+') and not line.startswith('+++')]
    
    if def_type == 'function':
        patterns = [
            rf'\b{escaped_name}\s*\(',
            rf'::{escaped_name}\s*\(',
            rf'\b{escaped_name}\b',
        ]
    elif def_type == 'class':
        patterns = [
            rf'\b{escaped_name}\b',
            rf'\b{escaped_name}\s*\(',
            rf'\b{escaped_name}\s*[*&]',
        ]
    else:
        patterns = [rf'\b{escaped_name}\b']
    
    for line in added_lines:
        for pattern in patterns:
            if re.search(pattern, line):
                return True
    return False


def _split_by_dependency_groups(dependency_groups: List[List[str]], file_diffs: Dict) -> List[Dict]:
    """ç›´æ¥æŒ‰ä¾èµ–ç»„æ‹†åˆ†ä¸ºå­PR
    
    ç­–ç•¥ï¼š
    1. æ¯ä¸ªä¾èµ–ç»„ï¼ˆlen>1ï¼‰ä½œä¸ºç‹¬ç«‹å­PR
    2. ç‹¬ç«‹æ–‡ä»¶ï¼šå¦‚æœæ€»ä»£ç é‡ä¸é«˜ï¼Œåˆå¹¶ä¸ºä¸€ä¸ªå­PRï¼›å¦åˆ™åˆ†å¼€
    """
    from src.utils.config import CONFIG
    
    sub_prs = []
    dep_group_count = 0
    
    # åˆ†ç¦»ä¾èµ–ç»„å’Œç‹¬ç«‹æ–‡ä»¶
    dependency_groups_only = []
    independent_files = []
    
    for group in dependency_groups:
        if len(group) > 1:
            dependency_groups_only.append(group)
        else:
            independent_files.extend(group)
    
    # å¤„ç†ä¾èµ–ç»„ - æ¯ä¸ªä½œä¸ºç‹¬ç«‹å­PR
    for group in dependency_groups_only:
        dep_group_count += 1
        group_diff = "\n".join([file_diffs.get(f, "") for f in group])
        group_size = len(group_diff.encode('utf-8'))
        
        sub_pr = {
            "title": f"[å­PR] ä¾èµ–ç»„ {dep_group_count} ({len(group)}ä¸ªç›¸äº’ä¾èµ–çš„æ–‡ä»¶)",
            "files": [{"path": f} for f in group],
            "diff": group_diff,
            "diff_size": group_size,
            "is_dependency_group": True
        }
        sub_prs.append(sub_pr)
    
    # å¤„ç†ç‹¬ç«‹æ–‡ä»¶
    if independent_files:
        # è®¡ç®—ç‹¬ç«‹æ–‡ä»¶æ€»ä»£ç é‡
        total_independent_size = sum(
            len(file_diffs.get(f, "").encode('utf-8')) for f in independent_files
        )
        
        # ä½¿ç”¨target_diff_sizeä½œä¸ºæ¯ç»„ç›®æ ‡å¤§å°
        splitting_config = CONFIG.get('pr_review', {}).get('splitting', {})
        target_size = splitting_config.get('target_diff_size', 50000)
        
        if total_independent_size <= target_size:
            # ä»£ç é‡ä¸é«˜ï¼Œåˆå¹¶ä¸ºä¸€ä¸ªå­PR
            combined_diff = "\n".join([file_diffs.get(f, "") for f in independent_files])
            sub_pr = {
                "title": f"[å­PR] ç‹¬ç«‹æ–‡ä»¶ç»„ ({len(independent_files)}ä¸ªç‹¬ç«‹æ–‡ä»¶)",
                "files": [{"path": f} for f in independent_files],
                "diff": combined_diff,
                "diff_size": total_independent_size,
                "is_dependency_group": False
            }
            sub_prs.append(sub_pr)
            print(f"        [åˆå¹¶] {len(independent_files)}ä¸ªç‹¬ç«‹æ–‡ä»¶åˆå¹¶ä¸º1ä¸ªå­PR (æ€»è®¡ {total_independent_size} bytes)")
        else:
            # ä»£ç é‡è¾ƒå¤§ï¼Œä½¿ç”¨è´ªå¿ƒç®—æ³•åˆ†ç»„ï¼ˆæ¯ç»„å°½é‡æ¥è¿‘target_sizeï¼‰
            grouped_files = _group_independent_files_by_size(independent_files, file_diffs, target_size)
            
            for i, group_files in enumerate(grouped_files, 1):
                group_diff = "\n".join([file_diffs.get(f, "") for f in group_files])
                group_size = len(group_diff.encode('utf-8'))
                
                if len(group_files) == 1:
                    title = f"[å­PR] ç‹¬ç«‹æ–‡ä»¶ {i}"
                else:
                    title = f"[å­PR] ç‹¬ç«‹æ–‡ä»¶ç»„ {i} ({len(group_files)}ä¸ªç‹¬ç«‹æ–‡ä»¶)"
                
                sub_pr = {
                    "title": title,
                    "files": [{"path": f} for f in group_files],
                    "diff": group_diff,
                    "diff_size": group_size,
                    "is_dependency_group": False
                }
                sub_prs.append(sub_pr)
            
            print(f"        [æ™ºèƒ½åˆ†ç»„] {len(independent_files)}ä¸ªç‹¬ç«‹æ–‡ä»¶åˆ†ä¸º{len(grouped_files)}ç»„ (æ€»è®¡ {total_independent_size} bytes)")
            for i, group_files in enumerate(grouped_files, 1):
                group_size = sum(len(file_diffs.get(f, "").encode('utf-8')) for f in group_files)
                print(f"            - ç»„{i}: {len(group_files)}ä¸ªæ–‡ä»¶, {group_size} bytes")
    
    return sub_prs


def _group_independent_files_by_size(independent_files: List[str], file_diffs: Dict, target_size: int) -> List[List[str]]:
    """ä½¿ç”¨è´ªå¿ƒç®—æ³•å°†ç‹¬ç«‹æ–‡ä»¶æŒ‰å¤§å°åˆ†ç»„
    
    ç­–ç•¥ï¼š
    1. æŒ‰æ–‡ä»¶å¤§å°é™åºæ’åˆ—
    2. ä½¿ç”¨First Fit Decreasingç®—æ³•ï¼Œå°†æ–‡ä»¶åˆ†é…åˆ°å°½é‡æ¥è¿‘target_sizeçš„ç»„ä¸­
    3. å°½é‡é¿å…å•æ–‡ä»¶ä¸€ç»„ï¼ˆé™¤éæ–‡ä»¶æœ¬èº«è¶…è¿‡target_sizeï¼‰
    """
    # è®¡ç®—æ¯ä¸ªæ–‡ä»¶çš„å¤§å°
    file_sizes = [(f, len(file_diffs.get(f, "").encode('utf-8'))) for f in independent_files]
    # æŒ‰å¤§å°é™åºæ’åˆ—
    file_sizes.sort(key=lambda x: x[1], reverse=True)
    
    groups = []
    
    for file_path, file_size in file_sizes:
        # å°è¯•æ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„ç»„åŠ å…¥ï¼ˆæ€»å¤§å°ä¸è¶…è¿‡target_sizeï¼‰
        placed = False
        for group in groups:
            group_size = sum(len(file_diffs.get(f, "").encode('utf-8')) for f in group)
            if group_size + file_size <= target_size:
                group.append(file_path)
                placed = True
                break
        
        # å¦‚æœæ²¡æœ‰åˆé€‚çš„ç»„ï¼Œåˆ›å»ºæ–°ç»„
        if not placed:
            groups.append([file_path])
    
    return groups


def _group_dependency_aware_by_directory(dependency_groups: List[List[str]], file_diffs: Dict, target_size: int) -> Dict:
    """ä¾èµ–å…³ç³»æ„ŸçŸ¥çš„ç›®å½•åˆ†ç»„
    
    å°†ä¾èµ–ç»„æŒ‰ç›®å½•åˆ†ç»„ï¼Œä½†ç¡®ä¿æ¯ä¸ªä¾èµ–ç»„å®Œæ•´æ€§
    """
    dir_groups = {}
    
    for dep_group in dependency_groups:
        # æ‰¾åˆ°è¿™ä¸ªä¾èµ–ç»„çš„ä¸»è¦ç›®å½•ï¼ˆå‡ºç°æœ€å¤šçš„ç›®å½•ï¼‰
        dir_counts = {}
        for file_path in dep_group:
            parts = file_path.split('/')
            dir_name = parts[0] if len(parts) > 1 else "æ ¹ç›®å½•"
            dir_counts[dir_name] = dir_counts.get(dir_name, 0) + 1
        
        # é€‰æ‹©æ–‡ä»¶æœ€å¤šçš„ç›®å½•
        main_dir = max(dir_counts, key=dir_counts.get)
        
        if main_dir not in dir_groups:
            dir_groups[main_dir] = {
                'files': [],
                'diff': ""
            }
        
        # å°†æ•´ä¸ªä¾èµ–ç»„åŠ å…¥è¯¥ç›®å½•
        for file_path in dep_group:
            dir_groups[main_dir]['files'].append({"path": file_path})
            if file_path in file_diffs:
                dir_groups[main_dir]['diff'] += file_diffs[file_path] + "\n"
    
    # è¿‡æ»¤æ‰å¤ªå°çš„ç»„
    filtered = {k: v for k, v in dir_groups.items() if len(v['files']) >= 2}
    
    return filtered if len(filtered) > 1 else dir_groups
