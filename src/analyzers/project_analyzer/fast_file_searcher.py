"""
é«˜æ€§èƒ½æ–‡ä»¶æœç´¢å™¨
ä½¿ç”¨ripgrepä½œä¸ºä¸»å¼•æ“ï¼ŒPythonä½œä¸ºfallback
"""

import os
import re
import subprocess
import json
from typing import List, Tuple, Optional, Set, Dict
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import shutil

DEFAULT_IGNORE_DIRS = {
    "node_modules", "__pycache__", ".git", ".venv", "venv", "env",
    "dist", "build", "out", ".next", ".nuxt", "target",
    "vendor", ".pytest_cache", ".mypy_cache", "coverage"
}

class FastFileSearcher:
    """
    é«˜æ€§èƒ½æ–‡ä»¶æœç´¢å·¥å…·
    ä¼˜å…ˆä½¿ç”¨ripgrepï¼Œå…¶æ¬¡Pythonå®ç°
    """
    
    def __init__(self):
        self.max_results = 300
        self.context_lines = 2
        self.max_file_size = 1_000_000  # 1MB
        self.min_file_size = 1
        self.ripgrep_available = self._check_ripgrep()
        self.file_cache = {}  # æ–‡ä»¶å†…å®¹ç¼“å­˜
        self.cache_max_size = 100  # æœ€å¤šç¼“å­˜100ä¸ªæ–‡ä»¶
        
    def _check_ripgrep(self) -> bool:
        """æ£€æŸ¥ripgrepæ˜¯å¦å¯ç”¨"""
        try:
            rg_path = shutil.which('rg')
            if not rg_path:
                print("[æœç´¢å¼•æ“] âš  ripgrep æœªæ‰¾åˆ°ï¼Œä½¿ç”¨Pythonæ¨¡å¼")
                return False
            
            result = subprocess.run(
                [rg_path, '--version'],
                capture_output=True,
                timeout=2,
                text=True
            )
            
            if result.returncode == 0:
                version = result.stdout.split('\n')[0]
                print(f"[æœç´¢å¼•æ“] âœ“ ripgrep å¯ç”¨ ({version})")
                return True
            else:
                print("[æœç´¢å¼•æ“] âš  ripgrep æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨Pythonæ¨¡å¼")
                return False
                
        except Exception as e:
            print(f"[æœç´¢å¼•æ“] âš  ripgrep æ£€æµ‹å¼‚å¸¸: {e}ï¼Œä½¿ç”¨Pythonæ¨¡å¼")
            return False
    
    def search(
        self, 
        directory: str, 
        regex: str, 
        file_pattern: str = "*"
    ) -> Dict[str, List[Dict]]:
        """
        æœç´¢æ–‡ä»¶
        
        Args:
            directory: æœç´¢ç›®å½•
            regex: æ­£åˆ™è¡¨è¾¾å¼
            file_pattern: æ–‡ä»¶æ¨¡å¼ï¼ˆæ”¯æŒå¤šä¸ªï¼Œç”¨é€—å·åˆ†éš”ï¼‰
            
        Returns:
            {æ–‡ä»¶è·¯å¾„: [åŒ¹é…é¡¹åˆ—è¡¨]}
        """
        if self.ripgrep_available:
            return self._search_with_ripgrep(directory, regex, file_pattern)
        else:
            return self._search_with_python(directory, regex, file_pattern)
    
    def batch_search(
        self,
        directory: str,
        patterns: List[Tuple[str, str]]  # [(regex, file_pattern), ...]
    ) -> Dict[str, Dict[str, List[Dict]]]:
        """
        æ‰¹é‡æœç´¢å¤šä¸ªæ¨¡å¼ï¼ˆå¹¶å‘ï¼‰
        
        Args:
            directory: æœç´¢ç›®å½•
            patterns: [(regex, file_pattern), ...] åˆ—è¡¨
            
        Returns:
            {pattern_key: {æ–‡ä»¶è·¯å¾„: [åŒ¹é…é¡¹åˆ—è¡¨]}}
        """
        results = {}
        
        if self.ripgrep_available:
            # ä½¿ç”¨å¹¶å‘ripgrepæœç´¢
            with ThreadPoolExecutor(max_workers=min(4, len(patterns))) as executor:
                future_to_pattern = {
                    executor.submit(
                        self._search_with_ripgrep, 
                        directory, 
                        regex, 
                        file_pattern
                    ): (regex, file_pattern)
                    for regex, file_pattern in patterns
                }
                
                for future in as_completed(future_to_pattern):
                    regex, file_pattern = future_to_pattern[future]
                    pattern_key = f"{regex}|{file_pattern}"
                    try:
                        results[pattern_key] = future.result()
                    except Exception as e:
                        print(f"[æ‰¹é‡æœç´¢] âš ï¸ æœç´¢å‡ºé”™ ({pattern_key}): {e}")
                        results[pattern_key] = {}
        else:
            # Pythonæ¨¡å¼ï¼šé¡ºåºæœç´¢ï¼ˆé¿å…å¹¶å‘è¯»å–æ–‡ä»¶å†²çªï¼‰
            for regex, file_pattern in patterns:
                pattern_key = f"{regex}|{file_pattern}"
                try:
                    results[pattern_key] = self._search_with_python(
                        directory, regex, file_pattern
                    )
                except Exception as e:
                    print(f"[æ‰¹é‡æœç´¢] âš ï¸ æœç´¢å‡ºé”™ ({pattern_key}): {e}")
                    results[pattern_key] = {}
        
        return results
    
    def _search_with_ripgrep(
        self,
        directory: str,
        regex: str,
        file_pattern: str = "*"
    ) -> Dict[str, List[Dict]]:
        """ä½¿ç”¨ripgrepè¿›è¡Œæœç´¢ï¼ˆé«˜æ€§èƒ½ï¼‰"""
        try:
            # æ„å»ºripgrepå‘½ä»¤
            cmd = [
                'rg',
                '--json',  # JSONè¾“å‡º
                '-e', regex,  # æœç´¢æ¨¡å¼
                '--context', str(self.context_lines),  # ä¸Šä¸‹æ–‡è¡Œæ•°
                '--max-count', str(self.max_results),  # æœ€å¤§ç»“æœæ•°
                '--max-filesize', '1M',  # æœ€å¤§æ–‡ä»¶å¤§å°
            ]
            
            # æ·»åŠ æ–‡ä»¶æ¨¡å¼è¿‡æ»¤
            if file_pattern and file_pattern != "*":
                # æ”¯æŒå¤šä¸ªæ–‡ä»¶æ¨¡å¼ï¼ˆé€—å·åˆ†éš”ï¼‰
                for pattern in file_pattern.split(','):
                    cmd.extend(['--glob', pattern.strip()])
            
            # æ·»åŠ å¿½ç•¥ç›®å½•
            for ignore_dir in DEFAULT_IGNORE_DIRS:
                cmd.extend(['--glob', f'!{ignore_dir}/**'])
            
            cmd.append(directory)
            
            # æ‰§è¡Œæœç´¢
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300  # 300ç§’è¶…æ—¶
            )
            
            # ripgrepè¿”å›ç ï¼š0=æ‰¾åˆ°ï¼Œ1=æœªæ‰¾åˆ°ï¼Œ2=é”™è¯¯
            if result.returncode in [0, 1]:
                return self._parse_ripgrep_json(result.stdout, directory)
            else:
                print(f"[ripgrep] âš ï¸ æœç´¢å¤±è´¥: {result.stderr}")
                return {}
                
        except subprocess.TimeoutExpired:
            print(f"[ripgrep] âš ï¸ æœç´¢è¶…æ—¶ï¼Œåˆ‡æ¢åˆ°Pythonæ¨¡å¼")
            return self._search_with_python(directory, regex, file_pattern)
        except Exception as e:
            print(f"[ripgrep] âš ï¸ æœç´¢é”™è¯¯: {e}ï¼Œåˆ‡æ¢åˆ°Pythonæ¨¡å¼")
            return self._search_with_python(directory, regex, file_pattern)
    
    def _parse_ripgrep_json(
        self,
        output: str,
        base_dir: str
    ) -> Dict[str, List[Dict]]:
        """è§£æripgrepçš„JSONè¾“å‡º"""
        results = {}
        current_file = None
        current_matches = []
        
        for line in output.strip().split('\n'):
            if not line:
                continue
            
            try:
                data = json.loads(line)
                msg_type = data.get('type')
                
                if msg_type == 'begin':
                    # æ–°æ–‡ä»¶å¼€å§‹
                    path_data = data.get('data', {}).get('path', {})
                    file_path = path_data.get('text', '')
                    if file_path:
                        current_file = os.path.relpath(file_path, base_dir)
                        current_matches = []
                
                elif msg_type == 'match':
                    # åŒ¹é…è¡Œ
                    if current_file:
                        match_data = data['data']
                        line_num = match_data.get('line_number', 0)
                        line_text = match_data.get('lines', {}).get('text', '').rstrip()
                        
                        # æ”¶é›†ä¸Šä¸‹æ–‡
                        current_matches.append({
                            'line_number': line_num,
                            'line': line_text,
                            'text': line_text,
                            'before': [],
                            'after': []
                        })
                
                elif msg_type == 'context':
                    # ä¸Šä¸‹æ–‡è¡Œ
                    if current_file and current_matches:
                        context_data = data['data']
                        context_line_num = context_data.get('line_number', 0)
                        context_text = context_data.get('lines', {}).get('text', '').rstrip()
                        
                        last_match = current_matches[-1]
                        if context_line_num < last_match['line_number']:
                            last_match['before'].append(context_text)
                        else:
                            last_match['after'].append(context_text)
                
                elif msg_type == 'end':
                    # æ–‡ä»¶ç»“æŸ
                    if current_file and current_matches:
                        results[current_file] = current_matches
                        current_file = None
                        current_matches = []
                        
            except json.JSONDecodeError:
                continue
        
        # å¤„ç†æœ€åä¸€ä¸ªæ–‡ä»¶
        if current_file and current_matches:
            results[current_file] = current_matches
        
        return results
    
    def _search_with_python(
        self,
        directory: str,
        regex: str,
        file_pattern: str = "*"
    ) -> Dict[str, List[Dict]]:
        """ä½¿ç”¨Pythonè¿›è¡Œæœç´¢ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰"""
        pattern = re.compile(regex)
        results = {}
        count = 0
        
        # è§£ææ–‡ä»¶æ¨¡å¼
        file_patterns = [p.strip() for p in file_pattern.split(',')]
        
        for root, dirs, files in os.walk(directory):
            # è¿‡æ»¤å¿½ç•¥ç›®å½•
            dirs[:] = [d for d in dirs if d not in DEFAULT_IGNORE_DIRS]
            
            for file in files:
                if count >= self.max_results:
                    break
                
                # æ–‡ä»¶æ¨¡å¼åŒ¹é…
                if file_pattern != "*":
                    import fnmatch
                    if not any(fnmatch.fnmatch(file, pat) for pat in file_patterns):
                        continue
                
                filepath = os.path.join(root, file)
                rel_path = os.path.relpath(filepath, directory)
                
                # æ€§èƒ½ä¼˜åŒ–ï¼šè·³è¿‡è¿‡å¤§æˆ–è¿‡å°çš„æ–‡ä»¶
                try:
                    file_size = os.path.getsize(filepath)
                    if file_size > self.max_file_size or file_size < self.min_file_size:
                        continue
                except OSError:
                    continue
                
                # ä½¿ç”¨ç¼“å­˜è¯»å–æ–‡ä»¶
                lines = self._get_file_content(filepath)
                if lines is None:
                    continue
                
                for i, line in enumerate(lines):
                    if pattern.search(line):
                        count += 1
                        if rel_path not in results:
                            results[rel_path] = []
                        
                        before = lines[max(0, i-self.context_lines):i]
                        after = lines[i+1:i+1+self.context_lines]
                        
                        results[rel_path].append({
                            'line_number': i + 1,
                            'line': line.rstrip(),
                            'text': line.rstrip(),
                            'before': [l.rstrip() for l in before],
                            'after': [l.rstrip() for l in after]
                        })
                        
                        if count >= self.max_results:
                            break
        
        return results
    
    def _get_file_content(self, filepath: str) -> Optional[List[str]]:
        """è·å–æ–‡ä»¶å†…å®¹ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        # æ£€æŸ¥ç¼“å­˜
        if filepath in self.file_cache:
            return self.file_cache[filepath]
        
        # è¯»å–æ–‡ä»¶
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # ç¼“å­˜ç®¡ç†ï¼šå…ˆè¿›å…ˆå‡º
            if len(self.file_cache) >= self.cache_max_size:
                # ç§»é™¤æœ€æ—©çš„ç¼“å­˜
                first_key = next(iter(self.file_cache))
                del self.file_cache[first_key]
            
            self.file_cache[filepath] = lines
            return lines
            
        except (UnicodeDecodeError, FileNotFoundError, PermissionError):
            return None
    
    def clear_cache(self):
        """æ¸…é™¤æ–‡ä»¶ç¼“å­˜"""
        self.file_cache.clear()
        print("[æœç´¢å¼•æ“] ğŸ—‘ï¸ ç¼“å­˜å·²æ¸…é™¤")


# å‘åå…¼å®¹ï¼šä¿æŒä¸åŸFileSearcherç›¸åŒçš„æ¥å£
class FileSearcher(FastFileSearcher):
    """å…¼å®¹æ€§åˆ«å"""
    pass
